{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding Box Visualization pre-requesite\n",
    "\n",
    "DATA_FOLDER = '../data/'\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "cloud_class_id = 0\n",
    "water_class_id = 1\n",
    "ground_class_id = 2\n",
    "\n",
    "category_index = {\n",
    "  cloud_class_id: {'id': cloud_class_id, 'name': 'cloud'},\n",
    "  water_class_id: {'id': water_class_id, 'name': 'water'},\n",
    "  ground_class_id: {'id': ground_class_id, 'name': 'ground'},\n",
    "}\n",
    "\n",
    "label_2_category = {'cloud':0,'water':1,'ground':2}\n",
    "\n",
    "width, heigth = (2592, 1944) # these dimension are from astro pi default image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing XML annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Get Image Annotation from XML Pascal VOC file\n",
    "def get_img_annotations(img_xml_annotations_path):\n",
    "  img_tree = ET.parse(img_xml_annotations_path)\n",
    "  img_root = img_tree.getroot()\n",
    "  labels_list = []\n",
    "  bbox_list = []\n",
    "  for child in img_root:\n",
    "    if child.tag == \"object\":\n",
    "      for element in child:\n",
    "        if element.tag == \"name\":\n",
    "          labels_list.append(element.text)\n",
    "        if element.tag == \"bndbox\":\n",
    "          bbox = []\n",
    "          for coordinates in element:\n",
    "            if coordinates.tag == \"xmin\":\n",
    "              bbox.append(coordinates.text)\n",
    "            if coordinates.tag == \"ymin\":\n",
    "              bbox.append(coordinates.text)\n",
    "            if coordinates.tag == \"xmax\":\n",
    "              bbox.append(coordinates.text)\n",
    "            if coordinates.tag == \"ymax\":\n",
    "              bbox.append(coordinates.text)\n",
    "          bbox_list.append(bbox)\n",
    "  return labels_list, bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Bounding Box so that it is normalized & invariant from image scale dimension\n",
    "def get_prepared_bbox(bbox, width, heigth):\n",
    "  for coord in bbox:\n",
    "    xmin_norm=int(bbox[0])/width\n",
    "    ymin_norm=int(bbox[1])/heigth\n",
    "    xmax_norm=int(bbox[2])/width\n",
    "    ymax_norm=int(bbox[3])/heigth\n",
    "  prepared_bbox = [ymin_norm,xmin_norm,ymax_norm,xmax_norm] # Object Detection Viz utils expected format\n",
    "  return prepared_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepaparation for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get name of astropi Jpeg images\n",
    "def get_images_name(data_folder):\n",
    "  data = os.listdir(data_folder)\n",
    "  images_file_list = [file for file in data if os.path.splitext(file)[1] != '.xml'] # remove xml file\n",
    "  images_file_list.sort()\n",
    "  return images_file_list\n",
    "\n",
    "# Get name of astropi XML annotations\n",
    "def get_bboxes_file_name(data_folder):\n",
    "  data = os.listdir(data_folder)\n",
    "  bbox_file_list = [file for file in data if os.path.splitext(file)[1] != '.jpg']\n",
    "  bbox_file_list.sort()\n",
    "  return bbox_file_list\n",
    "\n",
    "# Get a List of astropi numpy images\n",
    "def get_numpy_images(images_file,data_folder):\n",
    "  np_images_list = []\n",
    "  for image_file in images_file:\n",
    "    img_pil = Image.open(data_folder+image_file)\n",
    "    img_np = asarray(img_pil)\n",
    "    np_images_list.append(img_np)\n",
    "  return np_images_list\n",
    "\n",
    "# Get a List of bboxes & classes for images\n",
    "def get_gt_box_class(bbox_file_list,data_folder):\n",
    "  gt_boxes_list = []\n",
    "  classes_list = []\n",
    "  for bboxes in bbox_file_list: \n",
    "    classes,gt_boxes=get_img_annotations(data_folder+bboxes)\n",
    "    gt_boxes_np = np.array(gt_boxes,dtype=np.float32)\n",
    "    gt_boxes_list.append(gt_boxes_np)\n",
    "    classes_list.append(classes)\n",
    "  return gt_boxes_list, classes_list\n",
    "  \n",
    "# Get a List of class_id for images\n",
    "def get_class_id(classes_list): \n",
    "  classes_id_list = []\n",
    "  for classes in classes_list:\n",
    "    id_list  = []\n",
    "    for label in classes:\n",
    "      id = label_2_category[label]\n",
    "      id_list.append(id)\n",
    "    classes_id_list.append(id_list)\n",
    "  return classes_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Data from raw JPEG & XML files to lists\n",
    "images_list = get_images_name(DATA_FOLDER)\n",
    "np_images_list = get_numpy_images(images_list,DATA_FOLDER)\n",
    "bboxes_file_list = get_bboxes_file_name(DATA_FOLDER)\n",
    "gt_boxes_list, classes_list = get_gt_box_class(bboxes_file_list,DATA_FOLDER)\n",
    "classes_id_list = get_class_id(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resized_img(size_tuple,img_tensor):\n",
    "    resized_img = tf.image.resize(\n",
    "        img_tensor, size_tuple, preserve_aspect_ratio=False,\n",
    "        antialias=False, name=None\n",
    "    )\n",
    "    resized_img = tf.cast(resized_img,dtype=tf.uint8)\n",
    "    return resized_img\n",
    "\n",
    "def get_pad_resized_img(size,img_tensor):\n",
    "    resized_img = tf.image.resize_with_pad(\n",
    "        img_tensor, size,size,\n",
    "        antialias=False\n",
    "    )\n",
    "    resized_img = tf.cast(resized_img,dtype=tf.uint8)\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference from TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_path  = '../tflite/model.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tflite_prepared_image(image_name):\n",
    "  image_file = image_name + '.jpg'\n",
    "  img_pil = Image.open(DATA_FOLDER+image_file)\n",
    "  img_np = asarray(img_pil)\n",
    "  img_tensor = tf.expand_dims(tf.convert_to_tensor(\n",
    "    img_np, dtype=tf.float32), axis=0)\n",
    "  preprocessed_img =  get_pad_resized_img(320,img_tensor)\n",
    "  return preprocessed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tflite_predictions(image_name,tflite_interpreter):\n",
    "  # Prepare image\n",
    "  preprocessed_img = get_tflite_prepared_image(image_name)\n",
    "  input_tensor = preprocessed_img\n",
    "  input_tensor = tf.cast(input_tensor,dtype=tf.float32)\n",
    "  image_tflite_np = input_tensor.numpy()\n",
    "\n",
    "\n",
    "  input_details = tflite_interpreter.get_input_details()\n",
    "  output_details = tflite_interpreter.get_output_details() \n",
    "\n",
    "  # Prepare data for TFLite inference\n",
    "  input_shape = input_details[0]['shape'] # tflite model input shape\n",
    "  input_data = image_tflite_np.reshape(input_shape) # tflite model input data as numpy\n",
    "\n",
    "  # This load input_data into tlfite interpreter\n",
    "  interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "  interpreter.invoke()\n",
    "\n",
    "  # All useful Data from tflite inference: boxes, classes, scores\n",
    "  boxes = interpreter.get_tensor(output_details[1]['index'])\n",
    "  classes = interpreter.get_tensor(output_details[3]['index'])\n",
    "  scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "  return boxes, classes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image\n",
    "img = 'zz_astropi_1_photo_189'\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get Prediction\n",
    "boxes, classes, scores =  get_tflite_predictions(img,interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_df_prediction(prediction):\n",
    "  prediction_list = []\n",
    "  columns = ['ymin','xmin','ymax','xmax']\n",
    "  prediction_df = pd.DataFrame(prediction[0][0],columns=columns)\n",
    "  prediction_df['class'] = prediction[1][0].astype(np.int8)\n",
    "  prediction_df['score'] = prediction[2][0]\n",
    "  for index, row in prediction_df.iterrows():\n",
    "    prediction_list.append(list(row))\n",
    "  return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_prediction(prediction):\n",
    "  prediction_dico_list = []\n",
    "  i  = 0 \n",
    "  for (bbox,classe,score) in zip(prediction[0][0],prediction[1][0],prediction[2][0]):\n",
    "    prediction_dico = {'id':i,'ymin':bbox[0],'xmin':bbox[1],'ymax':bbox[2],'xmax':bbox[3],'class':classe,'score':score}\n",
    "    prediction_dico_list.append(prediction_dico)\n",
    "    i = i+1\n",
    "  return prediction_dico_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = get_tflite_predictions(img,interpreter)\n",
    "post_proc_prediction = post_process_prediction(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in post_proc_prediction:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference from TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycoral.utils import edgetpu\n",
    "from pycoral.adapters import common\n",
    "from pycoral.adapters import detect\n",
    "from pycoral.utils.dataset import read_label_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = '../tflite/efficientdet_bluelens_edgetpu.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load  TFLite model and allocate tensors.\n",
    "def load_tflite_model(model_path):\n",
    "    \"\"\"Helper function to load the tflite object detection model\n",
    "    Args:\n",
    "        model_path (str): path of tflite for tpu model\n",
    "    Returns:\n",
    "        interpreter: the actual tflite interpreter/model\n",
    "    \"\"\"\n",
    "    tflite_model_path  = model_path\n",
    "    interpreter = edgetpu.make_interpreter(tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(img_path,interpreter):\n",
    "    \"\"\"Prepare an image so that it's ready for interpreter inference\n",
    "    Args:\n",
    "        img_path (str): the path of the image to open\n",
    "        interpreter(object): the tflite interpreter\n",
    "    Returns:\n",
    "        img (PIL): the opened image\n",
    "        scale (tuple): ratio applied to image\n",
    "    \"\"\"\n",
    "    image = Image.open(img_path)\n",
    "    img, scale = common.set_resized_input(\n",
    "    interpreter, image.size, lambda size: image.resize(size, Image.ANTIALIAS))\n",
    "    return img,scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(img_path,interpreter):\n",
    "    \"\"\"Do inference on image using object detection interpreter/model\n",
    "    Args:\n",
    "        img_path (str): the path of the image to open\n",
    "        interpreter(object): the tflite interpreter\n",
    "    Returns:\n",
    "        obj_detection (object): the object detections done by interpreter/model\n",
    "    \"\"\"\n",
    "    img,scale = prepare_image(img_path,interpreter)\n",
    "    interpreter.invoke()\n",
    "    obj_detection = detect.get_objects(interpreter, score_threshold=0.31, image_scale=scale)\n",
    "    return obj_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading TFLite model\n",
    "interpreter = load_tflite_model(str(DIR_PATH)+'/'+MODEL_FILE)\n",
    "# Doing Prediction\n",
    "tpu_prediction = do_inference(picture_name+'.jpg',interpreter)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e2701736b123949a863c923c28e8a745e2e3fea60e41c7049110ab7a3eb278"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('bluelens_2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
