{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'models/research/object_detection/exporter_main_v2.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Export trained model as savedModel into export folder with exporter_main_v2.py\n",
    "!python models/research/object_detection/exporter_main_v2.py \\\n",
    "--pipeline_config_path output/pipeline.config \\\n",
    "--trained_checkpoint_dir output/checkpoint \\\n",
    "--output_directory export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'models/research/object_detection/export_tflite_graph_tf2.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python models/research/object_detection/export_tflite_graph_tf2.py \\\n",
    "  --pipeline_config_path output/pipeline.config \\\n",
    "  --trained_checkpoint_dir export/checkpoint \\\n",
    "  --output_directory tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/onnx/tensorflow-onnx\n",
    "!python -m tf2onnx.convert --saved-model ../tflite/saved_model --output ../tflite/model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLite Full integer Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get name os astropi images\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "from numpy import asarray\n",
    "import tensorflow as tf\n",
    "\n",
    "data_folder = '../data/'\n",
    "astro_data = os.listdir(data_folder)\n",
    "astro_images_file = [file for file in astro_data if os.path.splitext(file)[1] != '.xml'] # remove xml file\n",
    "astro_images_file.sort()\n",
    "astro_bbox_file = [file for file in astro_data if os.path.splitext(file)[1] != '.jpg']\n",
    "astro_bbox_file.sort()\n",
    "\n",
    "# Get a List of astropi numpy images\n",
    "astro_images_list = []\n",
    "for image_file in astro_images_file:\n",
    "  img_pil = Image.open(data_folder+image_file)\n",
    "  img_np = asarray(img_pil)\n",
    "  astro_images_list.append(img_np)\n",
    "\n",
    "# Get a numpy array of astropi numpy images\n",
    "astro_images_np = np.array(astro_images_list) # images as numpy array in case needed\n",
    "\n",
    "astro_image_tensors = [] # images tensor list from numpy array\n",
    "for astro_image_np in astro_images_list:\n",
    "  astro_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(\n",
    "      astro_image_np, dtype=tf.float32), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_resized_img(size,img_tensor):\n",
    "  \"\"\"resize a tensor image to model expected input shape\n",
    "  Args:\n",
    "      size (int): size to rescale tensor to width and heigth\n",
    "      img_tensor (tf.tensor): tf tensor to be rescaled\n",
    "  Returns:\n",
    "      resized_img: resized image tensor\n",
    "  \"\"\"\n",
    "  resized_img = tf.image.resize_with_pad(\n",
    "        img_tensor, size,size,\n",
    "        antialias=False\n",
    "    )\n",
    "  resized_img = tf.cast(resized_img,dtype=tf.uint8)\n",
    "  return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_image_tensors = [] # images tensor list from numpy array\n",
    "for astro_image_np in astro_images_list:\n",
    "  image_tensor = tf.convert_to_tensor(astro_image_np, dtype=tf.float32)\n",
    "  image_tensor = get_pad_resized_img(320,image_tensor)\n",
    "  astro_image_tensors.append(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = astro_image_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "  for data in tf.data.Dataset.from_tensor_slices((images)).batch(1).take(8):\n",
    "    yield [tf.dtypes.cast(data, tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "saved_model_dir = '../tflite/saved_model'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../tflite/model_full_quant.tflite', 'wb') as f:\n",
    "  f.write(tflite_quant_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e2701736b123949a863c923c28e8a745e2e3fea60e41c7049110ab7a3eb278"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('bluelens_2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
